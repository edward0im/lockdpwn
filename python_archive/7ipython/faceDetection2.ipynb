{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "#-*- coding: utf-8 -*-\n",
    "'''\n",
    "    python ==> 비주얼컴퓨팅, 프로젝트4 얼굴 사진 55x40 데이터를 700장 사용해 Deep Neural Network를 사용함으로써 예측모델을 만들어본 코드\n",
    "                             500번 반복하니 96% 정도의 예측율을 보여준다 굳굳\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy.misc\n",
    "import scipy.io\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------\n",
    "# train\n",
    "train_images = []\n",
    "tlabels = []\n",
    "\n",
    "# train Image 데이터 700장을 불러온다\n",
    "for num in range(1,701):\n",
    "    train_images.append(scipy.misc.imread('D:\\\\edward\\\\visualComputing_faceDetection\\\\train_image\\\\train_'+ str(num)+'.bmp'))\n",
    "\n",
    "# train Label 데이터를 불러온다\n",
    "with open(\"D:\\\\edward\\\\visualComputing_faceDetection\\\\train_label.txt\") as f:\n",
    "    line = [line.rstrip() for line in f]\n",
    "    tlabels.append(line)\n",
    "\n",
    "# Image 데이터와 Label 데이터를 numpy 데이터로 수정한다\n",
    "train_images = np.array(train_images)\n",
    "# LBP 연산을 위해 train_images2 선언해준다\n",
    "train_images2 = np.array(train_images)\n",
    "train_images = train_images.reshape(700, 2200, )\n",
    "\n",
    "\n",
    "tlabels = np.array(tlabels)     # tlabels = (1,700)\n",
    "tlabels = tlabels.reshape(700,1)\n",
    "\n",
    "# train Label 데이터를 [1 x 100] 의 행렬로 표현한다\n",
    "#           예를 들어 3이면 [0,0,1,0,.....,0] 과 같이 설정한다\n",
    "train_labels  = np.array(np.zeros(70000).reshape(700,100))\n",
    "for num in range(0,700):\n",
    "    train_labels[num][int(tlabels[num][0]) - 1] = 1\n",
    "\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "# test\n",
    "test_images = []\n",
    "testlabels = []\n",
    "\n",
    "\n",
    "# test Image 데이터 700장을 불러온다\n",
    "for num in range(1,701):\n",
    "    test_images.append(scipy.misc.imread('D:\\\\edward\\\\visualComputing_faceDetection\\\\test_image\\\\test_'+ str(num)+'.bmp'))\n",
    "\n",
    "\n",
    "# test Label 데이터를 불러온다\n",
    "with open(\"D:\\\\edward\\\\visualComputing_faceDetection\\\\test_label.txt\") as f:\n",
    "    line = [line.rstrip() for line in f]\n",
    "    testlabels.append(line)\n",
    "\n",
    "# Image 데이터와 Label 데이터를 numpy 데이터로 수정한다\n",
    "test_images = np.array(test_images)\n",
    "# LBP 연산을 위해 test_images2 선언해준다\n",
    "test_images2 = np.array(test_images)\n",
    "test_images = test_images.reshape(700, 2200, )\n",
    "\n",
    "testlabels = np.array(testlabels)     # tlabels = (1,700)\n",
    "testlabels = testlabels.reshape(700,1)\n",
    "\n",
    "# train Label 데이터를 [1 x 100] 의 행렬로 표현한다\n",
    "#           예를 들어 3이면 [0,0,1,0,.....,0] 과 같이 설정한다\n",
    "test_labels  = np.array(np.zeros(70000).reshape(700,100))\n",
    "for num in range(0,700):\n",
    "    test_labels[num][int(testlabels[num][0]) - 1] = 1\n",
    "\n",
    "\n",
    "# 중요! Image 데이터들은 0~255 사이의 값이므로 255로 나눠주면서 정규화를 한다. 학습이 매우 잘된다\n",
    "train_images = train_images / 255.\n",
    "test_images =  test_images / 255.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------\n",
    "\n",
    "_num_examples = 700   # 데이터 갯수\n",
    "_index_in_epoch = 0   # epoch\n",
    "_images = train_images  # Image 변수 \n",
    "_labels = train_labels  # Label 변수\n",
    "_epochs_completed = 0   \n",
    "\n",
    "# batch 연산을 수행하는 함수\n",
    "# 호출될 때마다 랜덤으로 batch_size의 (Image, Label) 데이터를 반환한다\n",
    "def next_batch(batch_size):\n",
    "    \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "    global _index_in_epoch\n",
    "    global _images\n",
    "    global _labels\n",
    "    global _epochs_completed\n",
    "\n",
    "    start = _index_in_epoch\n",
    "    _index_in_epoch += batch_size\n",
    "\n",
    "    if _index_in_epoch > _num_examples:\n",
    "      # Finished epoch\n",
    "      _epochs_completed += 1\n",
    "\n",
    "      # Shuffle the data\n",
    "      perm = np.arange(_num_examples)\n",
    "      np.random.shuffle(perm)\n",
    "      _images = _images[perm]\n",
    "      _labels = _labels[perm]\n",
    "\n",
    "      # Start next epoch\n",
    "      start = 0\n",
    "      _index_in_epoch = batch_size\n",
    "      assert batch_size <= _num_examples\n",
    "\n",
    "    end = _index_in_epoch\n",
    "    return _images[start:end], _labels[start:end]\n",
    "\n",
    "\n",
    "# 가중치를 초기화하는 함수 (정규분포 stddev=0.1로 초기화한다)\n",
    "def weight_variable(shape):\n",
    "\tinitial = tf.truncated_normal(shape, stddev=0.1)\n",
    "\treturn tf.Variable(initial)\n",
    "\n",
    "\n",
    "# 바이어스를 초기화하는 함수 (0.1로 초기화한다)\n",
    "def bias_variable(shape):\n",
    "\tinitial = tf.constant(0.1, shape=shape)\n",
    "\treturn tf.Variable(initial)\n",
    "\n",
    "\n",
    "# 컨벌루션을 실행하는 함수\n",
    "# padding = 'SAME' 입력과 출력의 이미지 크기가 같도록 해준다\n",
    "# (28,28) --> (28,28)\n",
    "# padding = 'VALID' 필터의 크기만큼 이미지 크기가 감소한다\n",
    "def conv2d_valid(x, W):\n",
    "\treturn tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='VALID')\n",
    "\n",
    "\n",
    "def conv2d_same(x, W):\n",
    "\treturn tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "\n",
    "# max pooling을 실행하는 함수\n",
    "def max_pool_2x2(x):\n",
    "\treturn tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------\n",
    "# Tensorflow 코드\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "x = tf.placeholder(\"float32\", [None, 2200]) # mnist data image of shape 55 x 40 = 2200\n",
    "y = tf.placeholder(\"float32\", [None, 100]) \n",
    "\n",
    "W = tf.Variable(tf.zeros([2200,100]))\n",
    "b = tf.Variable(tf.zeros([100]))\n",
    "\n",
    "\n",
    "# 1st conv layer ----------------------\n",
    "W_conv1 = weight_variable([8,5,1,32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "# -1 : 아직 디멘젼이 결정되지 않았다\n",
    "# 1 : 흑백이므로 1을 삽입한다. 칼라이면 3을 삽입한다\n",
    "# x은 2200x1인데 55x40x1로 행렬을 다시 만들어준다\n",
    "x_image = tf.reshape(x, [-1, 55, 40, 1])\n",
    "\n",
    "# y = x*w + b에 ReLU를 적용한다\n",
    "# (55,40) ==> (48,36)\n",
    "h_conv1 = tf.nn.relu(conv2d_valid(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "# (48,36) ==> (24, 18)\n",
    "\n",
    "\n",
    "\n",
    "# 2nd conv layer -----------------------\n",
    "W_conv2 = weight_variable([5,5,32,64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "# (24, 18) ==> (24, 18)\n",
    "h_conv2 = tf.nn.relu(conv2d_same(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "# (24, 18) ==> (12, 9)\n",
    "\n",
    "\n",
    "\n",
    "# 1st fully connected layer -----------------------\n",
    "W_fc1 = weight_variable([12*9*64, 3000])\n",
    "b_fc1 = bias_variable([3000])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 12*9*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "# 위 연산으로 1024x1의 벡터가 생성된다\n",
    "\n",
    "\n",
    "\n",
    "# Dropout ------------------------\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "\n",
    "\n",
    "# 2nd fully connected layer --------------\n",
    "W_fc2 = weight_variable([3000, 100])\n",
    "b_fc2 = bias_variable([100])\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# learning_rate 잘 설정하는게 중요하다.. 0.1로 하니 전혀 변화가 없었다\n",
    "learning_rate = 1e-4\n",
    "\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=y_conv))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "\n",
    "# 정답률을 계산한다  y_conv  vs  y\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 training_accuracy 0.0 cost 48.7996\n",
      "step 200 training_accuracy 0.66 cost 2.08699\n",
      "step 400 training_accuracy 1.0 cost 0.476292\n",
      "step 600 training_accuracy 1.0 cost 0.110921\n",
      "step 800 training_accuracy 1.0 cost 0.0185977\n",
      "step 1000 training_accuracy 1.0 cost 0.00748023\n",
      "step 1200 training_accuracy 1.0 cost 0.00504374\n",
      "step 1400 training_accuracy 1.0 cost 0.00210127\n",
      "step 1600 training_accuracy 1.0 cost 0.00101403\n",
      "step 1800 training_accuracy 1.0 cost 0.00135841\n",
      "step 2000 training_accuracy 1.0 cost 0.000515793\n",
      "step 2200 training_accuracy 1.0 cost 0.000594515\n",
      "step 2400 training_accuracy 1.0 cost 0.000271415\n",
      "step 2600 training_accuracy 1.0 cost 0.000249182\n",
      "step 2800 training_accuracy 1.0 cost 0.000133631\n",
      "step 3000 training_accuracy 1.0 cost 0.000218105\n",
      "step 3200 training_accuracy 1.0 cost 0.000257929\n",
      "step 3400 training_accuracy 1.0 cost 0.000186129\n",
      "step 3600 training_accuracy 1.0 cost 0.000156285\n",
      "step 3800 training_accuracy 1.0 cost 4.63163e-05\n",
      "step 4000 training_accuracy 1.0 cost 0.000117503\n",
      "step 4200 training_accuracy 1.0 cost 6.31332e-05\n",
      "step 4400 training_accuracy 1.0 cost 0.00016483\n",
      "step 4600 training_accuracy 1.0 cost 0.000153115\n",
      "step 4800 training_accuracy 1.0 cost 5.85573e-05\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------\n",
    "batch_size = 50      # 한 루프에 몇개의 (Image, Label) 데이터를 학습하는지 설정\n",
    "display_step = 200    # 루프를 돌면서 화면에 표시할 빈도 설정\n",
    "\n",
    "for i in range(5000):\n",
    "\tcostVal = 0.\n",
    "\tbatch = next_batch(batch_size)\n",
    "\t# 20번 돌릴 때마다 결과를 확인한다\n",
    "\tif i % display_step == 0:\n",
    "\t\ttrain_accuracy = sess.run(accuracy,feed_dict={x:batch[0], y:batch[1], keep_prob:1.0})\n",
    "\t\tcostVal = sess.run(cost, feed_dict={x: batch[0], y: batch[1], keep_prob:1.0})\n",
    "    \n",
    "\t\tprint('step', i , 'training_accuracy', train_accuracy,'cost', costVal)\n",
    "        \n",
    "        # 실제 학습과정 함수, dropout 50%를 토대로 학습한다\n",
    "\tsess.run(optimizer,feed_dict={x:batch[0],y:batch[1], keep_prob:0.5})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.992857\n"
     ]
    }
   ],
   "source": [
    "# 전부 학습이 끝나면 테스트 데이터를 넣어 정확도를 계산한다\n",
    "test_accuracy = sess.run(accuracy,feed_dict={x: test_images, y: test_labels, keep_prob: 1.0})\n",
    "print('test accuracy', test_accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  [23]\n",
      "Prediction:  [23]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMMAAAD8CAYAAADKUxDSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xed3ce48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#----------------------------------------------\n",
    "# 임의의 얼굴 하나를 출력한 다음 맞혀보는 코드 \n",
    "r = random.randint(0, _num_examples -1)\n",
    "print (\"Label: \", sess.run(tf.argmax(test_labels[r:r+1], 1)))\n",
    "print (\"Prediction: \", sess.run(tf.argmax(y_conv, 1), {x:test_images[r:r+1], keep_prob:1.0}))\n",
    "\n",
    "plt.imshow(test_images[r:r+1].reshape(55, 40), cmap='gray', interpolation='nearest')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
