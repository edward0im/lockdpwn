{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "#-*- coding: utf-8 -*-\n",
    "'''\n",
    "    python ==> 비주얼컴퓨팅, 프로젝트4 얼굴 사진 55x40 데이터를 700장 사용해 LBP 연산을 수행한 후 Deeper NN에 넣어본 코드\n",
    "\n",
    "'''\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy.misc\n",
    "import scipy.io\n",
    "import random\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------\n",
    "# train\n",
    "train_images = []\n",
    "tlabels = []\n",
    "\n",
    "# train Image 데이터 700장을 불러온다\n",
    "for num in range(1,701):\n",
    "    train_images.append(scipy.misc.imread('D:\\\\edward\\\\visualComputing_faceDetection\\\\train_image\\\\train_'+ str(num)+'.bmp'))\n",
    "\n",
    "# train Label 데이터를 불러온다\n",
    "with open(\"D:\\\\edward\\\\visualComputing_faceDetection\\\\train_label.txt\") as f:\n",
    "    line = [line.rstrip() for line in f]\n",
    "    tlabels.append(line)\n",
    "\n",
    "# Image 데이터와 Label 데이터를 numpy 데이터로 수정한다\n",
    "train_images = np.array(train_images)\n",
    "# LBP 연산을 위해 train_images2 선언해준다\n",
    "train_images2 = np.array(train_images)\n",
    "train_images = train_images.reshape(700, 2200, )\n",
    "\n",
    "\n",
    "tlabels = np.array(tlabels)     # tlabels = (1,700)\n",
    "tlabels = tlabels.reshape(700,1)\n",
    "\n",
    "# train Label 데이터를 [1 x 100] 의 행렬로 표현한다\n",
    "#           예를 들어 3이면 [0,0,1,0,.....,0] 과 같이 설정한다\n",
    "train_labels  = np.array(np.zeros(70000).reshape(700,100))\n",
    "for num in range(0,700):\n",
    "    train_labels[num][int(tlabels[num][0]) - 1] = 1\n",
    "\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "# test\n",
    "test_images = []\n",
    "testlabels = []\n",
    "\n",
    "\n",
    "# test Image 데이터 700장을 불러온다\n",
    "for num in range(1,701):\n",
    "    test_images.append(scipy.misc.imread('D:\\\\edward\\\\visualComputing_faceDetection\\\\test_image\\\\test_'+ str(num)+'.bmp'))\n",
    "\n",
    "\n",
    "# test Label 데이터를 불러온다\n",
    "with open(\"D:\\\\edward\\\\visualComputing_faceDetection\\\\test_label.txt\") as f:\n",
    "    line = [line.rstrip() for line in f]\n",
    "    testlabels.append(line)\n",
    "\n",
    "# Image 데이터와 Label 데이터를 numpy 데이터로 수정한다\n",
    "test_images = np.array(test_images)\n",
    "# LBP 연산을 위해 test_images2 선언해준다\n",
    "test_images2 = np.array(test_images)\n",
    "test_images = test_images.reshape(700, 2200, )\n",
    "\n",
    "testlabels = np.array(testlabels)     # tlabels = (1,700)\n",
    "testlabels = testlabels.reshape(700,1)\n",
    "\n",
    "# train Label 데이터를 [1 x 100] 의 행렬로 표현한다\n",
    "#           예를 들어 3이면 [0,0,1,0,.....,0] 과 같이 설정한다\n",
    "test_labels  = np.array(np.zeros(70000).reshape(700,100))\n",
    "for num in range(0,700):\n",
    "    test_labels[num][int(testlabels[num][0]) - 1] = 1\n",
    "\n",
    "\n",
    "# 중요! Image 데이터들은 0~255 사이의 값이므로 255로 나눠주면서 정규화를 한다. 학습이 매우 잘된다\n",
    "train_images = train_images / 255.\n",
    "test_images =  test_images / 255.\n",
    "\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "# LBP izing\n",
    "\n",
    "# 해당 사진 데이터의 크기를 받아온 후 lbp_img를 설정한다\n",
    "num_img, rows, cols = train_images2.shape\n",
    "\n",
    "newrows = int((rows-1)/2)\n",
    "newcols = int((cols-1)/2)\n",
    "\n",
    "# 트레이닝용 변수 선언\n",
    "lbp_img = np.array(np.zeros(700 * newcols * newrows).reshape(700, newrows, newcols))\n",
    "\n",
    "# 테스트용 변수 선언\n",
    "lbp_img_test = lbp_img\n",
    "\n",
    "# 한 점으로부터 2x2의 픽셀데이터를 반환하는 함수 \n",
    "def neighborPixels(img, x, y):\n",
    "    npixels = []\n",
    "\n",
    "    npixels.append(img[x-1, y-1])\n",
    "    npixels.append(img[x, y-1])\n",
    "    npixels.append(img[x+1, y-1])\n",
    "    npixels.append(img[x-1, y])\n",
    "    npixels.append(img[x+1, y])\n",
    "    npixels.append(img[x-1, y+1])\n",
    "    npixels.append(img[x, y+1])\n",
    "    npixels.append(img[x+1, y+1])\n",
    "\n",
    "    return np.array(npixels)\n",
    "\n",
    "\n",
    "# 중앙 center 점보다 neighbor_p 값이 크면 1을, 아니면 0을 반환하는 함수\n",
    "def thresholded(center, neighbor_p):\n",
    "    out = []\n",
    "    for a in neighbor_p:\n",
    "        if a > center:\n",
    "            out.append(1)\n",
    "        else:\n",
    "            out.append(0)\n",
    "\n",
    "    return out\n",
    "\n",
    "\n",
    "# LBP 메인 알고리즘\n",
    "for x in range(1, rows-1, 2):\n",
    "    for y in range(1, cols -1, 2):\n",
    "        for i in range(0, num_img - 1):\n",
    "            center = train_images2[i][x,y]   # 중앙 픽셀값을 받아온다\n",
    "            neighbor_p = neighborPixels(train_images2[i], x, y)  # 주변 점들의 값을 받아온다\n",
    "            values = thresholded(center, neighbor_p) # center 점보다 주변값이 크면 1 아니면 0 을 반환한다\n",
    "\n",
    "            weights = [1,2,4,8,16,32,64,128]\n",
    "            res = 0\n",
    "\n",
    "            for a in range(0, len(values)):\n",
    "                res += weights[a] + values[a]\n",
    "                lbp_img[i].itemset((x//2, y//2), res)\n",
    "\n",
    "\n",
    "# 데이터를 정규화시킨다\n",
    "lbp_img= lbp_img.reshape(700, 513)\n",
    "\n",
    "# LBP의 결과값이 전부 255보다 크므로 255를 빼서 데이터를 0 ~ 8 사이로 놓는다\n",
    "for i in range(0, num_img - 1):\n",
    "    for j in range(0, 513):\n",
    "            lbp_img[i][j] -= 255.\n",
    "\n",
    "# 데이터를 0 ~ 1 로 놓기 위해 8로 나눠준다\n",
    "lbp_img = lbp_img / 8.\n",
    "\n",
    "\n",
    "# Test용 LBP 연산도 똑같이 한다\n",
    "# LBP 메인 알고리즘\n",
    "for x in range(1, rows-1, 2):\n",
    "    for y in range(1, cols -1, 2):\n",
    "        for i in range(0, num_img - 1):\n",
    "            center = test_images2[i][x,y]   # 중앙 픽셀값을 받아온다\n",
    "            neighbor_p = neighborPixels(test_images2[i], x, y)  # 주변 점들의 값을 받아온다\n",
    "            values = thresholded(center, neighbor_p) # center 점보다 주변값이 크면 1 아니면 0 을 반환한다\n",
    "\n",
    "            weights = [1,2,4,8,16,32,64,128]\n",
    "            res = 0\n",
    "\n",
    "            for a in range(0, len(values)):\n",
    "                res += weights[a] + values[a]\n",
    "                lbp_img_test[i].itemset((x//2, y//2), res)\n",
    "\n",
    "\n",
    "# 데이터를 정규화시킨다\n",
    "lbp_img_test= lbp_img_test.reshape(700, 513)\n",
    "\n",
    "# LBP의 결과값이 전부 255보다 크므로 255를 빼서 데이터를 0 ~ 8 사이로 놓는다\n",
    "for i in range(0, num_img - 1):\n",
    "    for j in range(0, 513):\n",
    "            lbp_img_test[i][j] -= 255.\n",
    "\n",
    "# 데이터를 0 ~ 1 로 놓기 위해 8로 나눠준다\n",
    "lbp_img_test = lbp_img_test / 8.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------\n",
    "\n",
    "_num_examples = 700   # 데이터 갯수\n",
    "_index_in_epoch = 0   # epoch\n",
    "_images = lbp_img  # Image 변수 \n",
    "_labels = train_labels  # Label 변수\n",
    "_epochs_completed = 0   \n",
    "\n",
    "# batch 연산을 수행하는 함수\n",
    "# 호출될 때마다 랜덤으로 batch_size의 (Image, Label) 데이터를 반환한다\n",
    "def next_batch(batch_size):\n",
    "    \"\"\"Return the next `batch_size` examples from this data set.\"\"\"\n",
    "    global _index_in_epoch\n",
    "    global _images\n",
    "    global _labels\n",
    "    global _epochs_completed\n",
    "\n",
    "    start = _index_in_epoch\n",
    "    _index_in_epoch += batch_size\n",
    "\n",
    "    if _index_in_epoch > _num_examples:\n",
    "      # Finished epoch\n",
    "      _epochs_completed += 1\n",
    "\n",
    "      # Shuffle the data\n",
    "      perm = np.arange(_num_examples)\n",
    "      np.random.shuffle(perm)\n",
    "      _images = _images[perm]\n",
    "      _labels = _labels[perm]\n",
    "\n",
    "      # Start next epoch\n",
    "      start = 0\n",
    "      _index_in_epoch = batch_size\n",
    "      assert batch_size <= _num_examples\n",
    "\n",
    "    end = _index_in_epoch\n",
    "    return _images[start:end], _labels[start:end]\n",
    "\n",
    "\n",
    "# 가중치를 초기화하는 함수 (정규분포 stddev=0.1로 초기화한다)\n",
    "def weight_variable(shape):\n",
    "\tinitial = tf.truncated_normal(shape, stddev=0.1)\n",
    "\treturn tf.Variable(initial)\n",
    "\n",
    "\n",
    "# 바이어스를 초기화하는 함수 (0.1로 초기화한다)\n",
    "def bias_variable(shape):\n",
    "\tinitial = tf.constant(0.1, shape=shape)\n",
    "\treturn tf.Variable(initial)\n",
    "\n",
    "\n",
    "# 컨벌루션을 실행하는 함수\n",
    "# padding = 'SAME' 입력과 출력의 이미지 크기가 같도록 해준다\n",
    "# (28,28) --> (28,28)\n",
    "# padding = 'VALID' 필터의 크기만큼 이미지 크기가 감소한다\n",
    "def conv2d_valid(x, W):\n",
    "\treturn tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='VALID')\n",
    "\n",
    "\n",
    "def conv2d_same(x, W):\n",
    "\treturn tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "\n",
    "# max pooling을 실행하는 함수\n",
    "def max_pool_2x2(x):\n",
    "\treturn tf.nn.max_pool(x, ksize=[1,2,2,1], strides=[1,2,2,1], padding='SAME')\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#-----------------------------------------------------------------\n",
    "# Tensorflow 코드\n",
    "#-----------------------------------------------------------------\n",
    "\n",
    "x = tf.placeholder(\"float32\", [None, 513]) # mnist data image of shape 55 x 40 = 2200\n",
    "y = tf.placeholder(\"float32\", [None, 100]) \n",
    "\n",
    "W = tf.Variable(tf.zeros([513,100]))\n",
    "b = tf.Variable(tf.zeros([100]))\n",
    "\n",
    "\n",
    "# 1st conv layer ----------------------\n",
    "W_conv1 = weight_variable([8,4,1,32])\n",
    "b_conv1 = bias_variable([32])\n",
    "\n",
    "# -1 : 아직 디멘젼이 결정되지 않았다\n",
    "# 1 : 흑백이므로 1을 삽입한다. 칼라이면 3을 삽입한다\n",
    "# x은 513x1인데 27x19x1로 행렬을 다시 만들어준다\n",
    "x_image = tf.reshape(x, [-1, 27, 19, 1])\n",
    "\n",
    "# y = x*w + b에 ReLU를 적용한다\n",
    "# (27,19) ==> (20,16)\n",
    "h_conv1 = tf.nn.relu(conv2d_valid(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)\n",
    "# (20,16) ==> (10, 8)\n",
    "\n",
    "\n",
    "\n",
    "# 2nd conv layer -----------------------\n",
    "W_conv2 = weight_variable([5,5,32,64])\n",
    "b_conv2 = bias_variable([64])\n",
    "\n",
    "# (10, 8) ==> (10, 8)\n",
    "h_conv2 = tf.nn.relu(conv2d_same(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)\n",
    "# (10, 8) ==> (5, 4)\n",
    "\n",
    "\n",
    "\n",
    "# 1st fully connected layer -----------------------\n",
    "W_fc1 = weight_variable([5*4*64, 1000])\n",
    "b_fc1 = bias_variable([1000])\n",
    "\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 5*4*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)\n",
    "# 위 연산으로 3000x1의 벡터가 생성된다\n",
    "\n",
    "\n",
    "\n",
    "# Dropout ------------------------\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)\n",
    "\n",
    "\n",
    "\n",
    "# 2nd fully connected layer --------------\n",
    "W_fc2 = weight_variable([1000, 100])\n",
    "b_fc2 = bias_variable([100])\n",
    "y_conv = tf.matmul(h_fc1_drop, W_fc2) + b_fc2\n",
    "\n",
    "\n",
    "# learning_rate 잘 설정하는게 중요하다.. 0.1로 하니 전혀 변화가 없었다\n",
    "# 1000인 경우\n",
    "    # 1e-5 : 4500번, 15.4%\n",
    "    # 1e-4 : 4500번, 62.2%\n",
    "    # 5e-3 : 4500번, 24.7%  .. 먼가 이상하다\n",
    "    # 1e-3 : 4500번, 61.7%\n",
    "    # 1e-2 : 2100번에서 갑자기 cost가 0.0으로 변한다 (2000번, 21.2%)\n",
    "    # 1e-1 : 학습이 안되서 포기\n",
    "learning_rate = 1e-4\n",
    "\n",
    "\n",
    "cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(labels=y, logits=y_conv))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate).minimize(cost)\n",
    "\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "\n",
    "# 정답률을 계산한다  y_conv  vs  y\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0 training_accuracy 0.0 cost 9.07283\n",
      "step 1000 training_accuracy 1.0 cost 0.546801\n",
      "step 2000 training_accuracy 1.0 cost 0.0200156\n",
      "step 3000 training_accuracy 1.0 cost 0.00350146\n",
      "step 4000 training_accuracy 1.0 cost 0.00108978\n",
      "step 5000 training_accuracy 1.0 cost 0.000334885\n",
      "step 6000 training_accuracy 1.0 cost 0.00017008\n",
      "step 7000 training_accuracy 1.0 cost 7.88857e-05\n",
      "step 8000 training_accuracy 1.0 cost 7.61487e-05\n",
      "step 9000 training_accuracy 1.0 cost 2.58343e-05\n"
     ]
    }
   ],
   "source": [
    "#----------------------------------------------\n",
    "batch_size = 50      # 한 루프에 몇개의 (Image, Label) 데이터를 학습하는지 설정\n",
    "display_step = 1000    # 루프를 돌면서 화면에 표시할 빈도 설정\n",
    "\n",
    "for i in range(10000):\n",
    "\tcostVal = 0.\n",
    "\tbatch = next_batch(batch_size)\n",
    "\t# 20번 돌릴 때마다 결과를 확인한다\n",
    "\tif i % display_step == 0:\n",
    "\t\ttrain_accuracy = sess.run(accuracy,feed_dict={x:batch[0], y:batch[1], keep_prob:1.0})\n",
    "\t\tcostVal = sess.run(cost, feed_dict={x: batch[0], y: batch[1], keep_prob:1.0})\n",
    "    \n",
    "\t\tprint('step', i , 'training_accuracy', train_accuracy,'cost', costVal)\n",
    "        \n",
    "        # 실제 학습과정 함수, dropout 50%를 토대로 학습한다\n",
    "\tsess.run(optimizer,feed_dict={x:batch[0],y:batch[1], keep_prob:0.5})\n",
    "\n",
    "\n",
    "\n",
    "f\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.56\n"
     ]
    }
   ],
   "source": [
    "# 전부 학습이 끝나면 테스트 데이터를 넣어 정확도를 계산한다\n",
    "test_accuracy = sess.run(accuracy,feed_dict={x: lbp_img_test, y: test_labels, keep_prob: 1.0})\n",
    "print('test accuracy', test_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label:  [37]\n",
      "Prediction:  [53]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAMMAAAD8CAYAAADKUxDSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHaNJREFUeJztnXusHVd1xr9lY5MXduLYcYIfOA9j3jGQB1EqyANKmkCp\nFIRCpaqVIvmfFlFBBaiVqlJRiUjQFIm2qBBEJNKE8Ih4CKW44CgUVQGbpIFgEid2bMfxIyZ2YgIx\nsb37x92+mv2z71nn3Gufexy+nxT5rDNzZvbM3J351t5r7RWlFBljpBnT3QBjRgV3BmMq7gzGVNwZ\njKm4MxhTcWcwpuLOYEzFncGYypQ6Q0RcExEPR8SjEfGxY9UoY6aDmOwMdETMlPSIpHdIekLSTyS9\nv5Tyi4l+M3/+/LJs2bJxe9euXc32HTt2NPahQ4d62pNoc2PPmNH+v2DmzJk9t091/8xm+7o2t2Vk\nz5XbeW8PHjzY2AcOHGjs3/3udz1tHi9rP+/l6aef3thnnXVWY5900kmN3et6t2zZot27d6c38CXZ\nDj24RNKjpZSNkhQRd0h6j6QJO8OyZcu0du3acfszn/lMs/2mm25q7N/+9reN/fzzzzc2HxjhA3jp\nS1/a2Keeempjn3baaT1tPoA5c+Y09ste9rLGPvnkk3vaPD//IGbPnj3++SUvaR9Vr44j5X+cvHe/\n/vWvG/uZZ55p7L179zb2li1bGnvTpk2NzWfFa6M9d+7cxn73u9/d2B/4wAcae8WKFY39wgsvaCLe\n+ta3Trity1Rk0iJJWzv2E/W7hohYFRFrI2LtU089NYXTGXN8Oe4OdCnlP0opF5VSLlqwYMHxPp0x\nk2YqMmmbpCUde3H9bkL279+vjRs3jtt33nlns52v1v379zc2X+189VNKUMbwVcztlEWZjKLsOeWU\nU3r+PjsepUP3ejIfgP7HoBqfEpJt4//IFi1qRcDSpUsbe926dY1N/5DXs2fPnsa+/fbbG3vDhg2N\nffPNNzc2ZdNkmMqb4SeSlkfEuRExW9INkr415RYZM01M+s1QSjkQEX8l6b8kzZT0xVLKQ8esZcYM\nmanIJJVSvivpu8eoLcZMK1PqDIOye/dufeELXxi3ORxHn4C6knZ36FGS5s+f39jz5s1rbOrgzGfg\ndvoE9Bnok/B41PUcquX1d49PHyCbJ6CdDW1yaHbWrFmNzaFLtp3zAnwW99xzT2Nv3bq1sbP2Pfjg\ng4192223NfYnPvGJxu7e637naByOYUzFncGYijuDMZWh+gzPPvusVq9ePeH2TAdT+y1cuLCxqVMZ\nHkEfgDqX+2fhFfQJuD91L3U/t1Ondxkkjkk6UuPT5pwM/S+GwvD83J/+zuLFixv77W9/e2Pffffd\njc15CLaP/lg3rEc6cp7inHPOGf9sn8GYAXFnMKbizmBMZag+w8GDB5tQ4GzsnHY2lp1p/kHnDaiL\nObZOjZ/5ANxOqMu715/lYmTbqcEzfyzT2fQRaPNaGdt06aWXNvYPf/jDxqaPw7i1nTt3NvaPfvSj\nxr7++uuP1uye+M1gTMWdwZiKO4MxlaH6DIcOHWrGr+kz0GZsEceuzzzzzMbmuH/mE2TxOVnOMmH7\n6TPw91kqZi+yWKRMw/Na2Xb6GPTfMn8v8ymY07x8+fLGfuyxxxqbuS2/+tWvGvtTn/pUY5999tnj\nn5nSOhF+MxhTcWcwpuLOYExlqD5DKaXRjtSR9AG68SWSdMYZZzR2trQL83qpk6mLM11NXU7dTJ+A\nPsOgOQjd/fnbbF6A93bQdYuYI53ln2f+UJZf0dX40ljuSxcuVcPjbdvWpt9/9rOfHf/MuKeJ8JvB\nmIo7gzEVdwZjKkP3GboxJ4wdWrJkSWMzlog+ADU5dTF1dq/YH+nIeJgsL5fw+NnxMp3d9UmyNaJ4\nL7Jx/kHmNKTB127N1qXls+TfAteY4lwB7y19nAceeGD8829+85uJmt3gN4MxFXcGYyruDMZUhuoz\nRESjbbN5hEyzD+ozUGdnujs7XzaPkcUyZfUmevkoWc5zNg8waP5Cdi1kUH+NuSL8W3juuecam34A\nj9eNZeq3BonfDMZU3BmMqbgzGFMZqs8wc+bMZu6Aa+FQg1PrZbFD/Zy/C30Gnp86Nvt9r3WPpCPH\n9plj3WvsPLt23iteC8nazt8zBznLn8jWzSX0KZjv/uyzz/b8PePEJoPfDMZU0s4QEV+MiF0R8fPO\nd/MiYnVEbKj/ntHrGMacCPTzZviSpGvw3cckfb+UslzS96ttzAlN6jOUUu6NiGX4+j2Srqifb5V0\nj6SPZseaMWNGo8MH9QEynUyog6nRmRNNH4E2c6qzWKUsXihbJ6q7P6+9V5nco23PcjmyWJ+s9C7n\nAfj7bB6ENp8NY5c4z9BrXuV4r7W6sJSyvX7eIWlhr52NORGY8mhSKaVExIT/i46IVZJWSfloizHT\nyWTfDDsj4hxJqv9OmFfXrQPNV60xo8Rk/zq/JenPJX2y/vvNyRxkqnm7JIuZp67Ozj9ofE82DzFo\n/Ymubuaxs9ifbA6D4/JZfgPf6vSneP5nnnmmsbN5CsJ7l8359PJxjllsUkTcLul/Ja2IiCci4kaN\ndYJ3RMQGSW+vtjEnNP2MJr1/gk1XH+O2GDOteAbamMrQc6C7WpG6kbp20HyBbJ0ijoVTx2Zj75lP\nwLHxbK3VLEeg+/ss9oc5wrw2amrWbMvWgOLxBp0z4b3L5hl4fs7x8N73mtfI/JPxc/a1lzG/B7gz\nGFNxZzCmMq2zYFld5KxmQJYXS82/b9++ntupOzlWz3oRrCnH+hG0Ca+XOryXT0HN/9RTTzU24/+f\nfPLJxt66dWtjs/4Brz3zb7id/hNzmhlrlNV3yPIt+Puuj2OfwZgBcWcwpjL0pWJ6xSdRFnEolaWL\nKA04/MbjUUbx1U6ZxN9v2bKlsSmzXvnKVzb2lVde2dhMZeT1UZp0pRBf9Tt27Ghsyp7t27c39qZN\nm9SLLG6MQ6uUabwWhk888cQTjU0ZlZUxpkzi8pNsf79LSnbxm8GYijuDMRV3BmMqQ/cZqIu7ZCEG\nLEd07rnnNjZ1NfenD5ANnXL5Sw4/bty4sbF/+ctfNvaCBQsam+Vd6bNwCf6uTue56RPQh3j88ccb\nm5r6/PPPb2xqfMJnkaV5ZmmnHOamz8PyBCxxxntFf5HH7we/GYypuDMYU3FnMKYS/abEHQtOO+20\nsnLlygm3U4dyHoG6kWPR1NXUyRybZqncXmmX0pEhAPRR6ENs3ry5semTcHlN+hhdH4elXVkKlpqe\ncxoXXXRRY1Njc86Efxe8F/TvBl0ynvMU9Bnog3AegveOPlP33u/bt08HDhxIc4j9ZjCm4s5gTMWd\nwZjK0EO4u1qTupfj/lmpW+5/9tlnNzZ9hCz1MBtLZ3wO28OxcY71P/bYY41NXc+x/q4PwjkTamr6\nP4yTombfs2dPY3MOJluahfeO94L+XLYUDecNeL2vf/3rG/vhhx9ubPpjjIXqB78ZjKm4MxhTcWcw\npjJUn2HWrFmNrufYMWN3vve97zV2FjOfLXHIeYhs7Ju6PFuynj4OdSx1M7fTx3nta187/pk+Af0P\nam5eG9NA6SNMtSxVVkaKPgVtpoXSZ+A8BH2YN73pTY390EMPjX8+3kvSG/Oiw53BmIo7gzGVaS19\nu27dumY7Y3uyfAPqXMYCUfNnSxgS+gDZcpOZT8PrWbRoUWNfcMEFjd0dq1+4sC2OtHPnzsbOcoDZ\n1iwWifeOduYzZOUF6C/S5+G9+9nPftbYvHfc//rrrx///LWvfU394DeDMRV3BmMq/RQrWRIRayLi\nFxHxUER8sH7vWtDmRUU/PsMBSR8upfw0Il4maV1ErJb0FxqrBf3JiPiYxmpB9yx/u3///iZehzHy\n1LnMX+BYNMfas1gn6l7GGnH/s846q7GZA5Dp5qxMFXUur697viyXg2TzBFlbuRwloY/COCvO2WTz\nDPw9fYhsucs1a9Y0djc265gtL1lK2V5K+Wn9vE/SekmLNFYL+ta6262S/qSvMxozogw0mlSLo79R\n0n3qsxZ0t/QtR2eMGSX6dqAj4jRJX5f016WUZm6/jOmFo+aPdkvfug60GWX6ejNExCyNdYTbSinf\nqF/vjIhzSinbs1rQneM02i/LT8hK1XJtHGp46lpqxywHmTqdPgdztKnjs/wMxhtxLqBrZ2uTPv30\n0z3PzVyNbPl93ju2lbFOWdkrnp/7Z7kn9CnYXvpEq1evnrCtE9HPaFJIukXS+lLKP3c2Ha4FLU2h\nFrQxo0I/b4bLJf2ZpJ9FxAP1u7/VWO3nO2td6M2S3nd8mmjMcOinDvT/SJooBta1oM2LhqHGJs2Y\nMaPRvlkZJ46FM56Gmp66M4uxp8Y/77zzeu6fxQMR6nL6DPQDSFdX81z0GaiLqbF5rfS/6G/Rf+K1\ncE6Ev8/WZcrmDZh7kj1r3p/uWrSs6zERDscwpuLOYEzFncGYytDzGbrj1Rz3Z6wO41sYr8LfZ+ss\nUVdyO32WLH+BY++ct+DaRFnO9iD17qihWW+OuR+8VraVPgR9hKysMO8d96fNZ0Ufgj4Inz39Ld7b\nbm0N5k9PhN8MxlTcGYypuDMYUxn6WqtdMl1IncmxcmpsrpNEHUmdTM1PXU5Nz7zbFStWNDZ1+dq1\naxubY+PU3dTt3fOzbVk+AOdE3vCGNzR2VpeDPgPjwLI1qOhDcN6BPg3XTl26dGljc96Dfxu95mGy\n+aDD+M1gTMWdwZiKO4MxlaH7DF0dnI0tv+IVr2jsDRs2NPYVV1zR2NSxjJ+h7qQPwO2cx2D9Ber4\nT3/6042dxewT7t/1IegjcF/WrGY8DuchGIfFezeIP3M06K/x9+vXr29s+m/ddWal3MchXf+T80MT\n4TeDMRV3BmMq7gzGVIbuM3R1OMeiGW+Sja1v2rSpsW+44YbGpi6mdmR8DMfquT/XZbrlllsa+957\n721sjq1TF3NehfejO9ZP/4pzJlkcF2uc0R+6/PLLG5tzKFyjiveePgd9FuZb0B/k+egj0EehT0O7\n+7fTr7/hN4MxFXcGYyruDMZUhuozlFIa/UYfgDqW8SeMZ6Eu/dznPtfYF198cWO/7nWva2yOhVOz\ns44z60l064Yd7Xj0GRhblcVadcfms3VZea84rs+2dHOEJenb3/52YzPHmuseMfaJz47+1yWXXNLY\nzMegT8DjZbklvba7ppsxA+LOYEzFncGYylB9hoho9BvHzql7szX9WeeM8xKPPPJIY7MuGLVkluPM\nmH7OizD2KFtblX4Aj9dtT5YvkM3R0B9hvgLbltWo5jxHtj2LreK94vVxHoP0WoPL8wzGDIg7gzEV\ndwZjKkOPTepqO+pWjhVTB0/V7lX/QDrSZ2FONeE8QRY3T51MXc14oq7W5Tj/c88919jU1PQROM9A\njc/jcx6DOcn097L6dbSzmtzZ8bJ1m7rb7TMYMyD9FCs5KSJ+HBH/V0vffrx+f25E3BcRj0bEVyJi\ndnYsY0aZft4M+yVdVUq5UNJKSddExFsk3STp5lLKBZL2SLrx+DXTmONPP8VKiqTDgnJW/a9IukrS\nn9bvb5X0D5L+vdexIqLRhvQZqLmzeYYs9idbw3/Hjh09bepSas9sO3UvY6lYZ7rXXAFjgTZu3NjY\n2VqrzJFm23hv6T/x/Gw7Y5FY043wWfBe0geiz5DVuR40Z1rq02eIiJm1hNUuSaslPSZpbynl8NN6\nQmO1oY05YemrM5RSDpZSVkpaLOkSSa/q9wQRsSoi1kbE2uz/FsZMJwONJpVS9kpaI+kySadHxOF3\n3WJJ2yb4zXgdaIYfGDNKpD5DRCyQ9EIpZW9EnCzpHRpzntdIeq+kO9Rn6VvmM1AnsrNQx2Y5zByr\npk+ya1dbqvrJJ59sbOpoxvcwz5h1oHk++jTcn9Bn6baHbWcOMq+dcyScR+C9zvK/qcl3797dczuf\nHclqymW1MjL/bTLzDP1Mup0j6daImKmxN8mdpZTvRMQvJN0REZ+QdL/GakUbc8LSz2jSg5LeeJTv\nN2rMfzDmRYFnoI2pDD0Huqu7My1H3ZjlxXI743eo2fl76m7OC3DtIY6906fg8Rh7RF3O9nbH4nlt\nXCeWbeG8A9vCeYishgHzHdgenp/+Uub/ZXWgOe/BkcnJzCsQvxmMqbgzGFNxZzCmMlSf4dChQ40W\npE6lDu219ujRbOpKjoVnupNj81xbldt5PLYni1ViTgDH/rs228oa008//XRjZ7E9JKuvRx+Az4bX\nwnWRBp1D4vVyzieLZnA+gzFTwJ3BmIo7gzGVofsM3RgZ5h9w3J8+BW1q+s2bNzc2dTSPz99TZ9MH\nyGLo+13T8zD0QVgLudc8A+c0sloW1M30d3gtbBt9gqymG+d0WC+POdb0SXg9mT/W69ny2ibCbwZj\nKu4MxlTcGYypDN1n6GrdXvUIpCN1L8eWt21r84kY80+dzbpi2do72Vo/hDo609VZXbJue6jZM9jW\nLK4r89eyOtC0uS4t50W4Ti5zqulD8HhZ3Fr37yx7bofxm8GYijuDMRV3BmMqQ89n6GpTavhsrDzL\nL8jWbs10JnVvlqc76Ng74294/F45BfSXsnVjafPe0s7WHeKzyOZUeLzMX2Mux+LFixubc0DM6T4W\n+M1gTMWdwZiKO4MxlaH6DAcPHmxiXrK8W2ryLJ+AOjjT/NyejeVnPk22fij3Z14xx9a77WFuBv2j\nrD5ddi/o7wz6e5L5Q/QBGEfGe8V8CD57Hq/7rDzPYMyAuDMYU3FnMKYy9Nik7ng5dSR1KnUpx6oz\nH6Cf9nThWDd1ahaDT52b1ZQ7//zzG3vJkiWN/fjjj49/XrlyZbON8w5cJ4mamv4L52x4L7N8giyO\nLIPt4fnYvizfoVeOtHOgjRkQdwZjKu4MxlSGXge6qzWp86jtqFOzdZWyeBr+PqtBQB/ivPPOa2zW\nSctqIFD3vupVbQEkxuN060+wfgLj+3nt9CnWr1/f2LwWtp25IZzj4bVwniLLDcnqOvPeD1r/ofus\n7TMYMyB9d4Za5PD+iPhOtV0H2ryoGOTN8EFJ3Xet60CbFxV9+QwRsVjSdZL+SdKHYkzwDVwHWmr9\nBM4zDLq2alYbmFpx7ty5jc15AP6ea/9s2LChsVmTgDXiGC9Dnc3fX3DBBRNu5xpTnEe4//77e56b\n17J8+fLGpgbnukz0f17+8pc3dpZvTv+Qzz6b1yDZWkj9xiN16ffN8C+SPiLp8BnOVJ91oLulbyfT\nQGOGRdoZIuJdknaVUtZN5gTd0rdZJpgx00k/MulySX8cEddKOknSHEmfUa0DXd8OE9aBNuZEIQap\nhRURV0j6m1LKuyLiq5K+Xkq5IyI+J+nBUsq/9fr97NmzC9fL6ZKtrUodm41ln3rqqY3NsXrqYL65\nqMupuxk/Q53OOtUcS89yBnqNlQ/6ls3qx/FesOYb50Dow7B9zL/gPAbvVVYHmrkmvB7S/dvZvHmz\nnn/++TRwbSq65aMac6Yf1ZgP4TrQ5oRmoBnoUso9ku6pn10H2ryoGGo4RkQ0r7csDDcL8+Wrla9O\nvlppU8ZwtItpmYRDs2xvFlKepb12rzeTVFloCbdTcvJaOAzNslQkW0YnK1OcDZVm23uFlPcb2u/h\nHWMq7gzGVNwZjKlMawh3trxjFl4x6BLyWThHtuw6wynoU2TDn/QR6LP0SnvlsbMh8WzZnGyYlz5E\nlqLLkPHsXmfPMvOBSBba0w9+MxhTcWcwpuLOYExlqD7DrFmzmvJFXN6EOi8bm87mGbIw5Ezz8/yE\n4R5z5sxpbOpuhknz973SVLOyu7w3g5bgosZnmifvDa+NPkrmr2X+Ypaim80ddOdFtm7d2nPf8Tb0\ntZcxvwe4MxhTcWcwpjJUn2Hu3Lm69tprx+3Pf/7zzfZsrDqD+w86Fk8NP+hSNkx1pA/AeQrG//D8\nXR+H2zINTn8nW8KdIdZ8FvSvuJ3h7Dxe5v9lPkD2LDln85GPfGT884c+9KGevz2M3wzGVNwZjKm4\nMxhTGarPMGfOHL3zne8ct++6665mO+cdCHXjoDHx1MlZGaoM6nbqaPochGPnbE83TZVplnv27Ol5\nriwtMtPgWS4IfQAud8ntmb/Fe5/5EJyXePOb39zYV1111fhnzv9MeMy+9jLm9wB3BmMq7gzGVIbq\nM5xyyim68MILx+3uZyn3GUime7N8COpaan7GMnF/+iDZ8ifZ+amju34Al17JzpVpfmpuxhoRti1b\nQn7QuLJsyfkslum6665r7O68SL/L6vjNYEzFncGYijuDMZWhr5vU1eFXXnlls/0HP/hBY+/du3dK\n58vidQYlW+cpy+HO6JUDnZWazTQ9fYZMw9NmbsigcyxZTjbJ8tsZ10X/czL4zWBMxZ3BmIo7gzGV\noa+b1OXqq69u7C9/+cuNfd999zV2lsebxS5xbJ4MqsMJz8d4G56f25nv0G1PlgNMzc4c5kzDE+ZP\nUMPThyD0n7I5oUGW55ekyy67rLFf/epX9zx+P/jNYEyl3wKHj0vaJ+mgpAOllIsiYp6kr0haJulx\nSe8rpeyZ6BjGjDqDvBmuLKWsLKVcVO2PSfp+KWW5pO9X25gTlqn4DO+RdEX9fKvGiph8dJADsDTS\n2972tsZet66tqTjouH0W/0KfgDo3yxHI1h/NoI/AuPuuj5LF6vDaMn8lW4eJOcW8l/RRaGexUr3i\nsKS8JNl73/vexub9mQz9vhmKpO9FxLqIWFW/W1hK2V4/75A0cbE2Y04A+n0z/EEpZVtEnCVpdUT8\nsruxlFIi4qjDBbXzrJKkpUuXTqmxxhxP+nozlFK21X93SbpLY7XcdkbEOZJU/901wW/H60AvWLDg\n2LTamONA+maIiFMlzSil7Kuf/1DSP0r6lqQ/l/TJ+u83p9qY5cuXN/agY89ZvE22nmc2DzFoPE2m\nw6lzue5Stz1ZvnSWU5y1jXMonKfg+XmvsnmHzN/K1qi69NJLG/viiy/ueb7J0I9MWijprvqH8BJJ\n/1lKuTsifiLpzoi4UdJmSe875q0zZoiknaGWuD0iJLCU8itJVx/5C2NOTDwDbUxlWmOTCMfdmYNM\nXZrVZBu0Dtqg8TdZHnK21irzhnvlBGT15bJry+K6eO30X7KacFm9iGzeIYvTWrVqVWMfj8EYvxmM\nqbgzGFNxZzCmMlI+A/Na6TNk4/yEOjvzKQh1L30I/j6rI00fg3MDveJ1srZn+QOZhs9yNQat2zxV\n5s+f39grVqw4psc/Gn4zGFNxZzCm4s5gTGWkfIZ58+Y1NmPYMzIfIFvXKItdGjSPN6u7xuP1iunP\nNH6vNZcms3/mDw3qf5GsPawhR/t44DeDMRV3BmMq7gzGVGJQrTelk0U8pbFw7/mSdie7Txej3DZp\ntNs3qm17RSklDWYaamcYP2nE2s4qGyPFKLdNGu32jXLb+sEyyZiKO4MxlenqDP8xTefth1FumzTa\n7RvltqVMi89gzChimWRMZaidISKuiYiHI+LRiJj2tVkj4osRsSsift75bl5ErI6IDfXfM6apbUsi\nYk1E/CIiHoqID45Y+06KiB9HxP/V9n28fn9uRNxXn/FXImJ2dqxRYWidISJmSvpXSX8k6TWS3h8R\nrxnW+SfgS5KuwXejsqDyAUkfLqW8RtJbJP1lvV+j0r79kq4qpVwoaaWkayLiLZJuknRzKeUCSXsk\n3ThN7RuYYb4ZLpH0aCllYynld5Lu0NjixdNGKeVeSU/j6/dobCFl1X//ZKiNqpRStpdSflo/75O0\nXtKiEWpfKaX8upqz6n9F0lWSvla/n7b2TYZhdoZFkrZ27Cfqd6PGyC2oHBHLJL1R0n0aofZFxMyI\neEBjS4uulvSYpL2llMPht6P6jI+KHegelLGhtmkdbouI0yR9XdJfl1Ka9Vumu32llIOllJWSFmvs\nzf+q6WrLsWCYnWGbpCUde3H9btToa0HlYRARszTWEW4rpXxj1Np3mFLKXklrJF0m6fSIOJwnM6rP\n+KgMszP8RNLyOtowW9INGlu8eNQ4vKCydIwWVJ4MMZY9c4uk9aWUf+5sGpX2LYiI0+vnkyW9Q2N+\nzRpJhyuJTFv7JkUpZWj/SbpW0iMa05Z/N8xzT9Ce2yVtl/SCxvTtjZLO1NgozQZJ/y1p3jS17Q80\nJoEelPRA/e/aEWrfGyTdX9v3c0l/X78/T9KPJT0q6auSXjrdz7nf/zwDbUzFDrQxFXcGYyruDMZU\n3BmMqbgzGFNxZzCm4s5gTMWdwZjK/wML4+tbaMqrDgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0xcae5ac8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "#----------------------------------------------\n",
    "# 임의의 얼굴 하나를 출력한 다음 맞혀보는 코드 \n",
    "r = random.randint(0, _num_examples -1)\n",
    "print (\"Label: \", sess.run(tf.argmax(test_labels[r:r+1], 1)))\n",
    "print (\"Prediction: \", sess.run(tf.argmax(y_conv, 1), {x:lbp_img_test[r:r+1], keep_prob:1.0}))\n",
    "\n",
    "plt.imshow(test_images[r:r+1].reshape(55, 40), cmap='gray', interpolation='nearest')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
